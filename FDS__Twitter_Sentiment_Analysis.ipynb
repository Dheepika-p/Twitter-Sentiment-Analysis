{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FDS_ Twitter_Sentiment_Analysis.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "V3nr_FVL1wix"
      },
      "source": [
        "import pandas as pd\n",
        "import nltk\n",
        "tweets=pd.read_csv('Tweets.csv')\n",
        "tweets.head()\n",
        "\n",
        "tweets.isna().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g84P2Mp3ArP3"
      },
      "source": [
        "#delete columns which has lots of missing data\n",
        "del tweets['tweet_coord']\n",
        "del tweets['airline_sentiment_gold']\n",
        "del tweets['negativereason_gold']\n",
        "tweets.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "48jyeimAbWtK"
      },
      "source": [
        "airlines= ['US Airways','United','American','Southwest','Delta','Virgin America']\n",
        "plt.figure(1,figsize=(12, 12))\n",
        "for i in airlines:\n",
        "    indices= airlines.index(i)\n",
        "    \n",
        "    plt.subplot(2,3,indices+1)\n",
        "    new_df=tweets[tweets['airline']==i]\n",
        "    count=new_df['airline_sentiment'].value_counts()\n",
        "    Index = [1,2,3]\n",
        "    plt.bar(Index,count, color=['red', 'green', 'blue'])\n",
        "    plt.xticks(Index,['negative','neutral','positive'])\n",
        "    plt.ylabel('Mood Count')\n",
        "    plt.xlabel('Mood')\n",
        "    plt.title('Count of Moods of '+i)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yoCStrnVAjf6"
      },
      "source": [
        "# Data Pre Processing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K1mzLsbA2RFB"
      },
      "source": [
        "tweets_df=tweets.drop(tweets[tweets['airline_sentiment_confidence']<0.5].index,axis=0)\n",
        "tweets_df.shape\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zXJQ6zmdA0-Y"
      },
      "source": [
        "# Clean Your Text Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vQ3IrYaCCEx9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a7c03c1-ac66-4781-fcf2-dccc403a31cc"
      },
      "source": [
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "import string\n",
        "from nltk.stem import PorterStemmer\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1iU3rkrZCQRJ"
      },
      "source": [
        "stop_words=stopwords.words('english')\n",
        "punct=string.punctuation\n",
        "stemmer=PorterStemmer()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ulH1Z07tx_Ux"
      },
      "source": [
        "X=tweets_df['text']\n",
        "y=tweets_df['airline_sentiment']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R_LaCO9-CXOs"
      },
      "source": [
        "import re\n",
        "cleaned_data=[]\n",
        "for i in range(len(X)):\n",
        "  tweet=re.sub('[^a-zA-Z]',' ',X.iloc[i])\n",
        "  tweet=tweet.lower().split()\n",
        "  tweet=[stemmer.stem(word) for word in tweet if (word not in stop_words) and (word not in punct)]\n",
        "  tweet=' '.join(tweet)\n",
        "  cleaned_data.append(tweet)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F7wnkeYq-7s-"
      },
      "source": [
        "cleaned_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E5xrTrRF_Uzd"
      },
      "source": [
        "y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ds9kOK975_r0"
      },
      "source": [
        "sentiment_ordering = ['negative', 'neutral', 'positive']\n",
        "\n",
        "y = y.apply(lambda x: sentiment_ordering.index(x))\n",
        "print(y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vVzWuygc6ir1"
      },
      "source": [
        "y.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VHcbNyMDItFU"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "cv=CountVectorizer(max_features=3000,stop_words=['virginamerica','united','unit'])\n",
        "X_fin=cv.fit_transform(cleaned_data).toarray()\n",
        "X_fin.shape\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oz75D_bkGlK6"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train,X_test,y_train,y_test=train_test_split(X_fin,y,test_size=0.3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sf_vBD-T84Ge"
      },
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "dec_tree=DecisionTreeClassifier(random_state=0, max_depth=2)\n",
        "dec_tree = dec_tree.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5mnM14w__hSc"
      },
      "source": [
        "dec_log_predicted=dec_tree.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-6YigEWu9rds"
      },
      "source": [
        "import sklearn.metrics\n",
        "from mlxtend.plotting import plot_confusion_matrix\n",
        "\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "cf=classification_report(y_test,dec_log_predicted)\n",
        "cm=confusion_matrix(y_test,dec_log_predicted)\n",
        "plt.figure()\n",
        "plot_confusion_matrix(cm,figsize=(12,8), hide_ticks=True,cmap=plt.cm.Greens)\n",
        "plt.show()\n",
        "print(cf)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "htSVU87OKJ-W"
      },
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.model_selection import train_test_split\n",
        "model=MultinomialNB()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WJCj8PfLIWxu"
      },
      "source": [
        "model.fit(X_train,y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r5Pcx_AT_ACh"
      },
      "source": [
        "y_pred=model.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8o7mElQ79g17"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "from mlxtend.plotting import plot_confusion_matrix\n",
        "cf=classification_report(y_test,y_pred)\n",
        "cm=confusion_matrix(y_test,y_pred)\n",
        "plt.figure()\n",
        "plot_confusion_matrix(cm,figsize=(12,8), hide_ticks=True,cmap=plt.cm.Blues)\n",
        "plt.show()\n",
        "print(cf)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}